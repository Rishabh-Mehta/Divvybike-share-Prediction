{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3381226 entries, 0 to 3381225\nData columns (total 22 columns):\nUnnamed: 0             int64\ntrip_id                int64\nstart_time             object\nend_time               object\nbikeid                 int64\ntripduration           int64\nfrom_station_id        int64\nfrom_station_name      object\nto_station_id          int64\nto_station_name        object\nusertype               object\ngender                 object\nmonth                  int64\ndate                   object\nhour                   int64\nday                    int64\ndayofweek              int64\nweekend                int64\nage                    float64\nDailySnowDepth         float64\nHourlyTemperature      float64\nHourlyPrecipitation    float64\ndtypes: float64(4), int64(11), object(7)\nmemory usage: 567.5+ MB\n"
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout_count = pd.DataFrame(data.groupby(['from_station_id','date','month','day', 'hour'])['trip_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout_count.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>from_station_id</th>\n      <th>date</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>checkouts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2018-01-09</td>\n      <td>1</td>\n      <td>9</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2018-01-11</td>\n      <td>1</td>\n      <td>11</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2018-01-11</td>\n      <td>1</td>\n      <td>11</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2018-01-13</td>\n      <td>1</td>\n      <td>13</td>\n      <td>15</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>2018-01-14</td>\n      <td>1</td>\n      <td>14</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2018-01-20</td>\n      <td>1</td>\n      <td>20</td>\n      <td>14</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>2018-01-20</td>\n      <td>1</td>\n      <td>20</td>\n      <td>15</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>2018-01-20</td>\n      <td>1</td>\n      <td>20</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>2018-01-20</td>\n      <td>1</td>\n      <td>20</td>\n      <td>17</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>2018-01-21</td>\n      <td>1</td>\n      <td>21</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>2018-01-21</td>\n      <td>1</td>\n      <td>21</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>2018-01-21</td>\n      <td>1</td>\n      <td>21</td>\n      <td>13</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>2018-01-22</td>\n      <td>1</td>\n      <td>22</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2</td>\n      <td>2018-01-25</td>\n      <td>1</td>\n      <td>25</td>\n      <td>14</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>2018-01-25</td>\n      <td>1</td>\n      <td>25</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>2018-01-26</td>\n      <td>1</td>\n      <td>26</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>2018-01-26</td>\n      <td>1</td>\n      <td>26</td>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>2018-01-26</td>\n      <td>1</td>\n      <td>26</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>2018-01-27</td>\n      <td>1</td>\n      <td>27</td>\n      <td>12</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>2018-01-27</td>\n      <td>1</td>\n      <td>27</td>\n      <td>13</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>2018-01-27</td>\n      <td>1</td>\n      <td>27</td>\n      <td>15</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2</td>\n      <td>2018-01-27</td>\n      <td>1</td>\n      <td>27</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2</td>\n      <td>2018-01-27</td>\n      <td>1</td>\n      <td>27</td>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2</td>\n      <td>2018-01-28</td>\n      <td>1</td>\n      <td>28</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2</td>\n      <td>2018-01-28</td>\n      <td>1</td>\n      <td>28</td>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2</td>\n      <td>2018-01-31</td>\n      <td>1</td>\n      <td>31</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2</td>\n      <td>2018-02-02</td>\n      <td>2</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2</td>\n      <td>2018-02-16</td>\n      <td>2</td>\n      <td>16</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2</td>\n      <td>2018-02-16</td>\n      <td>2</td>\n      <td>16</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1191030</th>\n      <td>663</td>\n      <td>2018-12-17</td>\n      <td>12</td>\n      <td>17</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191031</th>\n      <td>663</td>\n      <td>2018-12-17</td>\n      <td>12</td>\n      <td>17</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191032</th>\n      <td>663</td>\n      <td>2018-12-17</td>\n      <td>12</td>\n      <td>17</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191033</th>\n      <td>663</td>\n      <td>2018-12-17</td>\n      <td>12</td>\n      <td>17</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191034</th>\n      <td>663</td>\n      <td>2018-12-18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191035</th>\n      <td>663</td>\n      <td>2018-12-18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191036</th>\n      <td>663</td>\n      <td>2018-12-19</td>\n      <td>12</td>\n      <td>19</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191037</th>\n      <td>663</td>\n      <td>2018-12-19</td>\n      <td>12</td>\n      <td>19</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191038</th>\n      <td>663</td>\n      <td>2018-12-19</td>\n      <td>12</td>\n      <td>19</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191039</th>\n      <td>663</td>\n      <td>2018-12-20</td>\n      <td>12</td>\n      <td>20</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191040</th>\n      <td>663</td>\n      <td>2018-12-20</td>\n      <td>12</td>\n      <td>20</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191041</th>\n      <td>663</td>\n      <td>2018-12-28</td>\n      <td>12</td>\n      <td>28</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191042</th>\n      <td>663</td>\n      <td>2018-12-30</td>\n      <td>12</td>\n      <td>30</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191043</th>\n      <td>664</td>\n      <td>2018-12-14</td>\n      <td>12</td>\n      <td>14</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191044</th>\n      <td>664</td>\n      <td>2018-12-14</td>\n      <td>12</td>\n      <td>14</td>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191045</th>\n      <td>664</td>\n      <td>2018-12-15</td>\n      <td>12</td>\n      <td>15</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191046</th>\n      <td>664</td>\n      <td>2018-12-16</td>\n      <td>12</td>\n      <td>16</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191047</th>\n      <td>664</td>\n      <td>2018-12-16</td>\n      <td>12</td>\n      <td>16</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191048</th>\n      <td>664</td>\n      <td>2018-12-17</td>\n      <td>12</td>\n      <td>17</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191049</th>\n      <td>664</td>\n      <td>2018-12-18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191050</th>\n      <td>664</td>\n      <td>2018-12-18</td>\n      <td>12</td>\n      <td>18</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191051</th>\n      <td>664</td>\n      <td>2018-12-20</td>\n      <td>12</td>\n      <td>20</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191052</th>\n      <td>664</td>\n      <td>2018-12-20</td>\n      <td>12</td>\n      <td>20</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191053</th>\n      <td>664</td>\n      <td>2018-12-20</td>\n      <td>12</td>\n      <td>20</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191054</th>\n      <td>664</td>\n      <td>2018-12-21</td>\n      <td>12</td>\n      <td>21</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191055</th>\n      <td>664</td>\n      <td>2018-12-22</td>\n      <td>12</td>\n      <td>22</td>\n      <td>13</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1191056</th>\n      <td>664</td>\n      <td>2018-12-22</td>\n      <td>12</td>\n      <td>22</td>\n      <td>16</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1191057</th>\n      <td>664</td>\n      <td>2018-12-22</td>\n      <td>12</td>\n      <td>22</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191058</th>\n      <td>664</td>\n      <td>2018-12-24</td>\n      <td>12</td>\n      <td>24</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1191059</th>\n      <td>664</td>\n      <td>2018-12-27</td>\n      <td>12</td>\n      <td>27</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1191060 rows × 6 columns</p>\n</div>",
      "text/plain": "         from_station_id        date  month  day  hour  checkouts\n0                      2  2018-01-06      1    6    13          1\n1                      2  2018-01-09      1    9    18          1\n2                      2  2018-01-11      1   11    11          4\n3                      2  2018-01-11      1   11    16          1\n4                      2  2018-01-13      1   13    15          2\n5                      2  2018-01-14      1   14    12          1\n6                      2  2018-01-20      1   20    14          9\n7                      2  2018-01-20      1   20    15          4\n8                      2  2018-01-20      1   20    16          1\n9                      2  2018-01-20      1   20    17          5\n10                     2  2018-01-21      1   21    10          5\n11                     2  2018-01-21      1   21    12          2\n12                     2  2018-01-21      1   21    13          2\n13                     2  2018-01-22      1   22    14          1\n14                     2  2018-01-25      1   25    14          2\n15                     2  2018-01-25      1   25    15          1\n16                     2  2018-01-26      1   26    11          1\n17                     2  2018-01-26      1   26    13          4\n18                     2  2018-01-26      1   26    16          1\n19                     2  2018-01-27      1   27    12          5\n20                     2  2018-01-27      1   27    13          8\n21                     2  2018-01-27      1   27    15          3\n22                     2  2018-01-27      1   27    16          2\n23                     2  2018-01-27      1   27    17          2\n24                     2  2018-01-28      1   28    11          4\n25                     2  2018-01-28      1   28    14          6\n26                     2  2018-01-31      1   31     6          1\n27                     2  2018-02-02      2    2    12          1\n28                     2  2018-02-16      2   16    12          1\n29                     2  2018-02-16      2   16    14          1\n...                  ...         ...    ...  ...   ...        ...\n1191030              663  2018-12-17     12   17     6          1\n1191031              663  2018-12-17     12   17     8          1\n1191032              663  2018-12-17     12   17     9          1\n1191033              663  2018-12-17     12   17    18          1\n1191034              663  2018-12-18     12   18     6          1\n1191035              663  2018-12-18     12   18    17          1\n1191036              663  2018-12-19     12   19     6          1\n1191037              663  2018-12-19     12   19     7          1\n1191038              663  2018-12-19     12   19    10          1\n1191039              663  2018-12-20     12   20     7          1\n1191040              663  2018-12-20     12   20     8          1\n1191041              663  2018-12-28     12   28     6          1\n1191042              663  2018-12-30     12   30    14          1\n1191043              664  2018-12-14     12   14    11          1\n1191044              664  2018-12-14     12   14    22          1\n1191045              664  2018-12-15     12   15     6          1\n1191046              664  2018-12-16     12   16     6          1\n1191047              664  2018-12-16     12   16    12          1\n1191048              664  2018-12-17     12   17    17          1\n1191049              664  2018-12-18     12   18    17          1\n1191050              664  2018-12-18     12   18    18          1\n1191051              664  2018-12-20     12   20    11          1\n1191052              664  2018-12-20     12   20    12          1\n1191053              664  2018-12-20     12   20    13          1\n1191054              664  2018-12-21     12   21     9          1\n1191055              664  2018-12-22     12   22    13          2\n1191056              664  2018-12-22     12   22    16          3\n1191057              664  2018-12-22     12   22    17          1\n1191058              664  2018-12-24     12   24    14          1\n1191059              664  2018-12-27     12   27    11          1\n\n[1191060 rows x 6 columns]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkout_count.rename(columns={'trip_id':'checkouts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1191060 entries, 0 to 1191059\nData columns (total 6 columns):\nfrom_station_id    1191060 non-null int64\ndate               1191060 non-null object\nmonth              1191060 non-null int64\nday                1191060 non-null int64\nhour               1191060 non-null int64\ntrip_id            1191060 non-null int64\ndtypes: int64(5), object(1)\nmemory usage: 54.5+ MB\n"
    }
   ],
   "source": [
    "checkout_count.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1191060, 5)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (41,49,51,75,89) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
    }
   ],
   "source": [
    "#importing weather data for 2018 chicago\n",
    "weather = pd.read_csv('weather1.csv')\n",
    "\n",
    "#Snow details are not available on hourly level only day level saving to new df\n",
    "snow_day = weather[weather.REPORT_TYPE == 'SOD  ']\n",
    "\n",
    "\n",
    "#cleaning weather data \n",
    "weather = weather[weather.REPORT_TYPE != 'SOD  '] #snow day\n",
    "weather = weather[weather.REPORT_TYPE != 'SOM  '] #snow month \n",
    "weather = weather[weather.REPORT_TYPE != 'SY-MT'] \n",
    "weather = weather[weather.REPORT_TYPE != 'FM-12'] \n",
    "weather = weather[weather.REPORT_TYPE != 'FM-16'] \n",
    "\n",
    "\n",
    "#Keeping only relevant columns in weather\n",
    "weather = weather[['DATE','HourlyDryBulbTemperature','HourlyPrecipitation']]\n",
    "weather.rename(columns={'HourlyDryBulbTemperature':'HourlyTemperature'},inplace=True)\n",
    "\n",
    "#Extracting  month ,day ,hour from DATE column\n",
    "weather['month'] = pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.month\n",
    "weather['day'] = pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.day\n",
    "weather['hour']=pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.hour\n",
    "weather.drop(columns='DATE',inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#converting HourlyPrecipitation with value 'T'traces to 0.01 and nan with ffill\n",
    "weather[weather['HourlyPrecipitation'] == 'T'] = 0.001\n",
    "weather['HourlyPrecipitation'] = weather['HourlyPrecipitation'].astype(float)\n",
    "\n",
    "weather['HourlyPrecipitation']=weather['HourlyPrecipitation'].fillna(method='ffill')\n",
    "\n",
    "weather['HourlyTemperature'] = weather['HourlyTemperature'].fillna(method='ffill')\n",
    "\n",
    "#Cleaned weather data 2018\n",
    "weather.to_csv('weather_final.csv')\n",
    "\n",
    "#selecting relevent columns from snow_day data frame\n",
    "snow_day = snow_day[['DATE','DailySnowDepth']]\n",
    "\n",
    "#Extracting date from DATE \n",
    "#snow_day['date'] = pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.date\n",
    "snow_day['month'] = pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.month\n",
    "snow_day['day'] = pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.day\n",
    "snow_day.drop(columns='DATE',inplace=True)\n",
    "snow_day.to_csv('snow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkout = checkout_count.merge(snow_day ,on=['month','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:946: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n  'representation', UserWarning)\n"
    }
   ],
   "source": [
    "data_checkout = data_checkout.merge(weather,on=['month','day','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkout.index = data_checkout['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>from_station_id</th>\n      <th>date</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>trip_id</th>\n      <th>DailySnowDepth</th>\n      <th>HourlyTemperature</th>\n      <th>HourlyPrecipitation</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-06</th>\n      <td>2</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>3</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>14</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>23</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>24</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>26</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>28</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>35</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>38</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>39</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            from_station_id        date  month  day  hour  trip_id  \\\ndate                                                                 \n2018-01-06                2  2018-01-06      1    6    13        1   \n2018-01-06                3  2018-01-06      1    6    13        3   \n2018-01-06               14  2018-01-06      1    6    13        1   \n2018-01-06               23  2018-01-06      1    6    13        1   \n2018-01-06               24  2018-01-06      1    6    13        3   \n2018-01-06               26  2018-01-06      1    6    13        1   \n2018-01-06               28  2018-01-06      1    6    13        1   \n2018-01-06               35  2018-01-06      1    6    13        1   \n2018-01-06               38  2018-01-06      1    6    13        5   \n2018-01-06               39  2018-01-06      1    6    13        1   \n\n            DailySnowDepth  HourlyTemperature  HourlyPrecipitation  \ndate                                                                \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  "
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkout.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_checkout.rename(columns={'trip_id':'checkouts'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>from_station_id</th>\n      <th>date</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>checkouts</th>\n      <th>DailySnowDepth</th>\n      <th>HourlyTemperature</th>\n      <th>HourlyPrecipitation</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-06</th>\n      <td>2</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>3</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>14</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>23</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-06</th>\n      <td>24</td>\n      <td>2018-01-06</td>\n      <td>1</td>\n      <td>6</td>\n      <td>13</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            from_station_id        date  month  day  hour  checkouts  \\\ndate                                                                   \n2018-01-06                2  2018-01-06      1    6    13          1   \n2018-01-06                3  2018-01-06      1    6    13          3   \n2018-01-06               14  2018-01-06      1    6    13          1   \n2018-01-06               23  2018-01-06      1    6    13          1   \n2018-01-06               24  2018-01-06      1    6    13          3   \n\n            DailySnowDepth  HourlyTemperature  HourlyPrecipitation  \ndate                                                                \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  \n2018-01-06             1.0               14.0                  0.0  "
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_checkout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 1191060 entries, 2018-01-06 to 2018-01-12\nData columns (total 9 columns):\nfrom_station_id        1191060 non-null int64\ndate                   1191060 non-null object\nmonth                  1191060 non-null int64\nday                    1191060 non-null int64\nhour                   1191060 non-null int64\ncheckouts              1191060 non-null int64\nDailySnowDepth         1191060 non-null float64\nHourlyTemperature      1191060 non-null float64\nHourlyPrecipitation    1191060 non-null float64\ndtypes: float64(3), int64(5), object(1)\nmemory usage: 90.9+ MB\n"
    }
   ],
   "source": [
    "data_checkout.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_checkout['checkouts']\n",
    "data_checkout.drop(columns=['checkouts','date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(data_checkout,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.78263894, 3.17913107, 2.27415123, ..., 3.5165859 , 2.54811718,\n       4.40011596])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-aef718b1e78b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# plt.tight_layout()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# conf_matrix = metrics.confusion_matrix(ytest,y_pred)\n",
    "# sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.title('Confusion matrix')\n",
    "# plt.tight_layout()\n",
    "\n",
    "accuracy = metrics.accuracy_score(ytest, y_pred)\n",
    "error = 1 - accuracy\n",
    "precision = metrics.precision_score(ytest, y_pred, average = None)\n",
    "recall = metrics.recall_score(ytest, y_pred, average = None)\n",
    "F1_score = metrics.f1_score(ytest, y_pred, average = None)\n",
    "print([accuracy, error, precision, recall, F1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the metrics of the Linear Regression model\n",
    "\n",
    "\n",
    "# Mean Squared Error\n",
    "lm_mse = mean_squared_error(ytest,y_pred)\n",
    "\n",
    "# r2 score\n",
    "lm_r2 = r2_score(ytest,y_pred)\n",
    "\n",
    "# Mean Absolute Error\n",
    "lm_mean_ae = mean_absolute_error(ytest,y_pred)\n",
    "\n",
    "# Median Absolute Error\n",
    "lm_median_ae = median_absolute_error(ytest,y_pred)\n",
    "\n",
    "a = metrics.accuracy_score(ytest,y_pred)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mean Squared Error = 16.48542954658469\nr2 = 0.05628954977154854\nMean Absolute Error= 1.9780799544672694\nMedian Absolute Error 1.3789056507020374\n"
    }
   ],
   "source": [
    "\n",
    "print('Mean Squared Error =', lm_mse)\n",
    "print('r2 =', lm_r2)\n",
    "print('Mean Absolute Error=', lm_mean_ae)\n",
    "print('Median Absolute Error', lm_median_ae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(normalize=True)\n",
    "lasso.fit(xtrain, ytrain)\n",
    "y_pred = lasso.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Mean Squared Error\n",
    "lm_mse = mean_squared_error(ytest,y_pred)\n",
    "\n",
    "# r2 score\n",
    "lm_r2 = r2_score(ytest,y_pred)\n",
    "\n",
    "# Mean Absolute Error\n",
    "lm_mean_ae = mean_absolute_error(ytest,y_pred)\n",
    "\n",
    "# Median Absolute Error\n",
    "lm_median_ae = median_absolute_error(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mean Squared Error = 17.46885480886229\nr2 = -1e-05\nMean Absolute Error= 2.088292617435617\nMedian Absolute Error 1.8355798316505587\n"
    }
   ],
   "source": [
    "\n",
    "print('Mean Squared Error =', lm_mse)\n",
    "print('r2 =', round(lm_r2,5))\n",
    "print('Mean Absolute Error=', lm_mean_ae)\n",
    "print('Median Absolute Error', lm_median_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}