{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "#loading data for year 2018\n",
    "q1_2018 = pd.read_csv('Divvy_Trips_2018_Q1.csv')\n",
    "q2_2018 = pd.read_csv('Divvy_Trips_2018_Q2.csv')\n",
    "q3_2018 = pd.read_csv('Divvy_Trips_2018_Q3.csv')\n",
    "q4_2018 = pd.read_csv('Divvy_Trips_2018_Q4.csv')\n",
    "\n",
    "#Q1 data has different column names , making them consistent accross all the data frames by renaming\n",
    "q1_2018=q1_2018.rename(columns={'01 - Rental Details Rental ID':'trip_id',\n",
    "'01 - Rental Details Local Start Time':'start_time',\n",
    "'01 - Rental Details Local End Time':'end_time',\n",
    "'01 - Rental Details Bike ID':'bikeid',\n",
    "'01 - Rental Details Duration In Seconds Uncapped':'tripduration',\n",
    "'03 - Rental Start Station ID':'from_station_id',\n",
    "'02 - Rental End Station ID':'to_station_id',\n",
    "'03 - Rental Start Station Name':'from_station_name',\n",
    "'02 - Rental End Station Name':'to_station_name',\n",
    "'User Type':'usertype',\n",
    "'Member Gender':'gender',\n",
    "'05 - Member Details Member Birthday Year':'birthyear'})\n",
    "\n",
    "#COmbinig 2018 data to single df\n",
    "data_2018 = pd.concat([q1_2018,q2_2018,q3_2018,q4_2018],axis=0)\n",
    "\n",
    "#Converting to datetime\n",
    "data_2018.start_time = pd.to_datetime(data_2018.start_time)\n",
    "data_2018.end_time  = pd.to_datetime(data_2018.end_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning trip duration columns for values like 2,904.0\n",
    "data_2018['tripduration'] = (data_2018.end_time - data_2018.start_time).dt.seconds\n",
    "#Extracting  month ,day ,hour ,date from start_time\n",
    "data_2018['month'] = data_2018.start_time.dt.month\n",
    "data_2018['date']   = data_2018.start_time.dt.date\n",
    "data_2018['hour'] = data_2018.start_time.dt.hour\n",
    "data_2018['day'] = data_2018.start_time.dt.day\n",
    "data_2018['DayofWeek'] = data_2018.start_time.dt.dayofweek\n",
    "\n",
    "#Finding is a day is a weekend\n",
    "data_2018['weekend']=np.where(data_2018.start_time.dt.weekday > 4 , 1, 0)\n",
    "\n",
    "#Calculating age in 2018 and dropping birthyear\n",
    "data_2018['age'] = np.where(data_2018.birthyear > 0 ,2018 - data_2018['birthyear'],0)\n",
    "data_2018.drop(columns='birthyear',inplace=True)\n",
    "#shape (3603082, 17)\n",
    "\n",
    "#dropping observations with age >80 as riders cannot be more than age of 80\n",
    "data_2018=data_2018[data_2018['age'] <80]\n",
    "# shape (3601532, 17)\n",
    "\n",
    "#dropping observatoins with Subscribers having age 0\n",
    "data_2018['age_']=(np.logical_and(data_2018['usertype']=='Subscriber',data_2018['age'] == 0))\n",
    "data_2018 = data_2018[data_2018.age_ ==False]\n",
    "data_2018.drop(columns='age_',inplace=True)\n",
    "#shape (3598317, 17)\n",
    "\n",
    "#Final Trip details for 2018\n",
    "data_2018.to_csv('data_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing weather data for 2018 chicago\n",
    "weather = pd.read_csv('weather1.csv')\n",
    "\n",
    "#Snow details are not available on hourly level only day level saving to new df\n",
    "snow_day = weather[weather.REPORT_TYPE == 'SOD  ']\n",
    "\n",
    "\n",
    "#cleaning weather data \n",
    "weather = weather[weather.REPORT_TYPE != 'SOD  '] #snow day\n",
    "weather = weather[weather.REPORT_TYPE != 'SOM  '] #snow month \n",
    "weather = weather[weather.REPORT_TYPE != 'SY-MT'] \n",
    "weather = weather[weather.REPORT_TYPE != 'FM-12'] \n",
    "weather = weather[weather.REPORT_TYPE != 'FM-16'] \n",
    "\n",
    "\n",
    "#Keeping only relevant columns in weather\n",
    "weather = weather[['DATE','HourlyDryBulbTemperature','HourlyPrecipitation']]\n",
    "weather.rename(columns={'HourlyDryBulbTemperature':'HourlyTemperature'},inplace=True)\n",
    "\n",
    "#Extracting  month ,day ,hour from DATE column\n",
    "weather['month'] = pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.month\n",
    "weather['day'] = pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.day\n",
    "weather['hour']=pd.to_datetime(weather.DATE,format='%Y-%m-%d').dt.hour\n",
    "weather.drop(columns='DATE',inplace=True)\n",
    "\n",
    "\n",
    "#converting HourlyPrecipitation with value 'T'traces to 0.01 and nan with ffill\n",
    "\n",
    "\n",
    "weather['HourlyPrecipitation'] = np.where(weather['HourlyPrecipitation'] == 'T',0.01,weather['HourlyPrecipitation'])\n",
    "weather['HourlyPrecipitation'] = weather['HourlyPrecipitation'].astype(float)\n",
    "\n",
    "weather['HourlyPrecipitation']=weather['HourlyPrecipitation'].fillna(method='ffill')\n",
    "\n",
    "weather['HourlyTemperature'] = weather['HourlyTemperature'].fillna(method='ffill')\n",
    "\n",
    "#Cleaned weather data 2018\n",
    "weather.to_csv('weather_final.csv')\n",
    "\n",
    "#selecting relevent columns from snow_day data frame\n",
    "snow_day = snow_day[['DATE','DailySnowDepth']]\n",
    "\n",
    "#Extracting date from DATE \n",
    "snow_day['date'] = pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.date\n",
    "snow_day['month']= pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.month\n",
    "snow_day['day'] = pd.to_datetime(snow_day.DATE,format='%Y-%m-%d').dt.day\n",
    "snow_day.drop(columns='DATE',inplace=True)\n",
    "snow_day.to_csv('snow.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging trip details with snow_day , this gives amount of DailySnowDepth for each day\n",
    "data_merged = data_2018.merge(snow_day ,on=['date','month','day'])\n",
    "#shape (3598317, 18)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging trip details with weather adding HourlyTemperature and HourlyPrecipitation\n",
    "data_merged = data_merged.merge(weather,on=['month','day','hour'],how='inner')\n",
    "#Shape (3588777, 19)\n",
    "\n",
    "\n",
    "#dropping previous index column\n",
    "data_merged.drop(data_merged.iloc[:,0:1],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_2018.merge(snow_day ,on='date')\n",
    "#Shape(3598317, 17)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging trip details with weather adding HourlyTemperature and HourlyPrecipitation\n",
    "data_merged = data_merged.merge(weather,on=['month','day','hour'],how='inner')\n",
    "#Shape (3588777, 20)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting final preprocessed data  \n",
    "data_merged.to_csv('data_merged.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}